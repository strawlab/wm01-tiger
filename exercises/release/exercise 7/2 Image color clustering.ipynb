{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Clustering to do *color quantization* using K-Means\n",
    "\n",
    "\n",
    "First, we review the clustering example from lecture. We will perform a pixel-wise Vector Quantization (VQ) of an image of the summer palace (China), reducing the number of colors required to show the image from 96,615\n",
    "unique colors to a smaller number, while preserving the overall appearance quality.\n",
    "\n",
    "In this example, pixels are represented in a 3D-space and K-means is used to find k color clusters. In the image processing literature, the **codebook** obtained from K-means (the cluster centers) is called the color palette. Using an unsigned 8 bit integer (called a byte), up to 256 colors can be addressed (numbered 0-255), whereas an RGB encoding requires 3 bytes per pixel. The GIF file format, for example, uses such a palette.\n",
    "\n",
    "For comparison, a quantized image using a random codebook (colors picked up randomly) is also shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: Robert Layton <robertlayton@gmail.com>\n",
    "#          Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#          Mathieu Blondel <mathieu@mblondel.org>\n",
    "#\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.datasets import load_sample_image\n",
    "from sklearn.utils import shuffle\n",
    "from scipy import ndimage\n",
    "import imageio\n",
    "from time import time\n",
    "\n",
    "# Load the Summer Palace photo\n",
    "china = load_sample_image(\"china.jpg\")\n",
    "\n",
    "# Convert to floats instead of the default 8 bits integer coding. Dividing by\n",
    "# 255 is important so that plt.imshow behaves works well on float data (need to\n",
    "# be in the range [0-1])\n",
    "china = np.array(china, dtype=np.float64) / 255\n",
    "\n",
    "# Load image and transform to a 2D numpy array which is w*h rows and d columns.\n",
    "h, w, d = original_shape = tuple(china.shape)\n",
    "assert d == 3\n",
    "image_array = np.reshape(china, (w * h, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the color intensity values for a sample of 1000 pixels\n",
    "\n",
    "# First, let's sample 1000 pixels randomly\n",
    "image_array_sample = shuffle(image_array, random_state=0)[:1000]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12,3))\n",
    "\n",
    "axes[0].plot(image_array_sample[:,0], image_array_sample[:,1], '.')\n",
    "axes[0].set_xlabel('red')\n",
    "axes[0].set_ylabel('green')\n",
    "\n",
    "axes[1].plot(image_array_sample[:,0], image_array_sample[:,2], '.')\n",
    "axes[1].set_xlabel('red')\n",
    "axes[1].set_ylabel('blue')\n",
    "\n",
    "axes[2].plot(image_array_sample[:,1], image_array_sample[:,2], '.')\n",
    "axes[2].set_xlabel('green')\n",
    "axes[2].set_ylabel('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use this function later to recreate a full color image given a particular codebook.\n",
    "\n",
    "def recreate_image(codebook, labels, h, w):\n",
    "    \"\"\"Recreate the (compressed) image from the code book & labels\"\"\"\n",
    "    d = codebook.shape[1]\n",
    "    image = np.zeros((h, w, d))\n",
    "    label_idx = 0\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            image[i][j] = codebook[labels[label_idx]]\n",
    "            label_idx += 1\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_colors = 10\n",
    "\n",
    "# Here with use the KMeans algorithm to cluster a subset of our\n",
    "print(\"Fitting model on a small sub-sample of the data\")\n",
    "t0 = time()\n",
    "image_array_sample = shuffle(image_array, random_state=0)[:1000]\n",
    "kmeans = KMeans(n_clusters=n_colors, random_state=0).fit(image_array_sample)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "# Get labels for all points\n",
    "print(\"Predicting color indices on the full image (k-means)\")\n",
    "t0 = time()\n",
    "labels = kmeans.predict(image_array)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "print('np.max(labels)',np.max(labels))\n",
    "\n",
    "codebook_random = shuffle(image_array, random_state=0)[:n_colors]\n",
    "print(\"Predicting color indices on the full image (random)\")\n",
    "t0 = time()\n",
    "labels_random = pairwise_distances_argmin(codebook_random,\n",
    "                                          image_array,\n",
    "                                          axis=0)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "print('np.max(labels_random)',np.max(labels_random))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all results, alongside original image\n",
    "figsize = (10,10)\n",
    "plt.figure(1,figsize=figsize)\n",
    "plt.clf()\n",
    "ax = plt.axes([0, 0, 1, 1])\n",
    "plt.axis('off')\n",
    "plt.title('Original image (96,615 colors)')\n",
    "plt.imshow(china)\n",
    "\n",
    "plt.figure(2,figsize=figsize)\n",
    "plt.clf()\n",
    "ax = plt.axes([0, 0, 1, 1])\n",
    "plt.axis('off')\n",
    "plt.title('Quantized image (%d colors, K-Means)' % n_colors)\n",
    "plt.imshow(recreate_image(kmeans.cluster_centers_, labels, h, w))\n",
    "\n",
    "plt.figure(3,figsize=figsize)\n",
    "plt.clf()\n",
    "ax = plt.axes([0, 0, 1, 1])\n",
    "plt.axis('off')\n",
    "plt.title('Quantized image (%d colors, Random)' % n_colors)\n",
    "plt.imshow(recreate_image(codebook_random, labels_random, h, w))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color quantization for coffee bean detection and localization\n",
    "\n",
    "We now want to use color quantization to segment an image into specific objects based on their color.\n",
    "\n",
    "We now load the image `beans` as so:\n",
    "\n",
    "```\n",
    "beans = imageio.imread('data/IMG_4272.JPG')\n",
    "```\n",
    "\n",
    "This is a copy of the code above modified to use the `beans` data (instead of the `china` data). Below we show the original image and a color quantized image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beans = imageio.imread('coffee_beans.JPG')\n",
    "\n",
    "beans = np.array(beans, dtype=np.float64) / 255\n",
    "\n",
    "# Load image and transform to a 2D numpy array which is w*h rows and d columns.\n",
    "h, w, d = beans_shape = tuple(beans.shape)\n",
    "assert d == 3\n",
    "image_array = np.reshape(beans, (w * h, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 Choose `n_colors` to perform well in subsequent tasks.\n",
    "\n",
    "We have a goal of choosing `n_colors` (the number of clusters, *k*) which will make the task of detecting beans easiest. So change this variable and re-run the following cells until you have a good value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d223e9eb113554dfd10cada250c66730",
     "grade": true,
     "grade_id": "cell-4e76633799a3843b",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here with use the KMeans algorithm to cluster a subset of our\n",
    "print(\"Fitting model on a small sub-sample of the data\")\n",
    "t0 = time()\n",
    "image_array_sample = shuffle(image_array, random_state=0)[:1000]\n",
    "kmeans = KMeans(n_clusters=n_colors, random_state=0).fit(image_array_sample)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "# Get labels for all points\n",
    "print(\"Predicting color indices on the full image (k-means)\")\n",
    "t0 = time()\n",
    "labels = kmeans.predict(image_array)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "print('np.max(labels)',np.max(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this task (bean detection) it will be useful to also plot the labels, so \n",
    "# we shape them to have the same size as our images.\n",
    "\n",
    "labels_shaped = labels.copy()\n",
    "labels_shaped.shape = (h,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the original, reconstructed and label images\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, figsize=(10,20))\n",
    "axes[0].set_title('Original image')\n",
    "axes[0].imshow(beans)\n",
    "\n",
    "axes[1].set_title('Quantized image (%d colors, K-Means)' % n_colors)\n",
    "axes[1].imshow(recreate_image(kmeans.cluster_centers_, labels, h, w))\n",
    "\n",
    "axes[1].set_title('Labels (%d colors, K-Means)' % n_colors)\n",
    "cax=axes[2].imshow(labels_shaped, cmap='jet')\n",
    "fig.colorbar(cax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image processing for bean detection\n",
    "\n",
    "Now that we have quantized our colors, perhaps we can use a specific quantized color to simply an image analysis task.\n",
    "\n",
    "In this case, our \"labels\" indicate which cluster each pixel belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 Based on the label plot above, pick the label number with the best value for our couting task.\n",
    "\n",
    "Put this in the `best_label` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "55b9d4257936aa3d40774b4296978b07",
     "grade": true,
     "grade_id": "cell-a1545b44baba6de9",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 The following steps do blurring, thresholding, erosion, and connected components labeling to \"clean up\" the labels. Run and adjust these steps, if necessary, to make an image showing the beans with their centers roughly like this:\n",
    "\n",
    "(It is not required, or expected, that your image will look exactly like this.)\n",
    "\n",
    "See if you can get even better bean localizations.\n",
    "\n",
    "![bean-centers.png](bean-centers.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded = labels_shaped==best_label\n",
    "plt.imshow(thresholded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = ndimage.gaussian_filter(thresholded.astype(np.float64), sigma=8.0)\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded = im > 0.5\n",
    "plt.imshow(thresholded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eroded = thresholded\n",
    "for i in range(10):\n",
    "    eroded = ndimage.binary_erosion(eroded)\n",
    "plt.imshow(eroded.astype(np.uint8))\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "labels, num_labels = ndimage.label(thresholded)\n",
    "plt.imshow(labels, cmap='jet')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coms = ndimage.center_of_mass(thresholded, labels, index=range(1,num_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "plt.imshow(beans)\n",
    "plt.colorbar()\n",
    "for com in coms:\n",
    "    ax.plot([com[1]],[com[0]], 'x')\n",
    "plt.savefig('bean-centers.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
